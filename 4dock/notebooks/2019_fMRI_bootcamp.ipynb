{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# fMRI analysis bootcamp!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the plan for the day?\n",
    "This tutorial follows the FEAT GUI. I don't expect that you would use the GUI forever but it is a nice way to introudce yourself to modeling.  \n",
    "1. Input data (what are we even working with)\n",
    "2. Output data (what are we expecting to get)\n",
    "3. Preprocessing . \n",
    " - fMRIPREP\n",
    " - What do we do with fMRIPREP?\n",
    " - What if I don't want to do fMRIPREP?\n",
    "4. Prestats\n",
    " - B0 unwrapping\n",
    " - Spatial smoothing\n",
    " - Intensity normalization\n",
    " - Temportal Filtering\n",
    "5. Registration\n",
    " - fMRIPREP work around  \n",
    "6. FILM\n",
    "7. Stats overview\n",
    "8. First level stats\n",
    " - Confounds\n",
    " - Modeling\n",
    "9. Second level modeling\n",
    "10. Third Level modeling\n",
    "11. Randomiz(s)e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Input data (what are we even working with)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DICOM (.dcm): \n",
    "- Digital Imaging and Communications in Medicine. Imaging standard. \n",
    "- A data with object with a lot of attributes (name, ID, modality, pixel data)\n",
    "- Usually the pixel image is a single image, however multi-frame data is possible\n",
    "- Not open   \n",
    "\n",
    "## Nifti (.nii):\n",
    "- Open file format\n",
    "- First 3 dimensions are x,y,z \n",
    "- Fourth is time\n",
    "- Header contains lots of useful information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! fslhd <example file>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Really good summary here:  \n",
    "https://brainder.org/2012/09/23/the-nifti-file-format/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Output data (what are we expecting)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEAT Directory structure \n",
    "\n",
    "https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FEAT/UserGuide#Stats_.28First-level.29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There are a lot of options, some helpful and some less \n",
    "We will focus on the basics, but later if you want to chat more _outlandish_ methods I am happy to. Presently we will focus on:\n",
    "- Quality control (QA)\n",
    "- Distortion correction\n",
    "- Slice timing correction\n",
    "- Motion correction\n",
    "- Spatial smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality Control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at your images! Make sure your imaging center is performing routine checks. Usual artifacts you will see are:\n",
    "- Striping\n",
    "-- Could be due to spiking\n",
    "- Ghosting (especially if you have a population that moves alot)\n",
    "-- Offset in the K space in EPI acquisition \n",
    "-- AKA you don't know where the data is in space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MRQC\n",
    "https://github.com/poldracklab/mriqc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No matter what there is no substitution for looking at your images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept Check: Looking at good and bad images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need data to look at here maybe some QA reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distortion correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often times refered to as 'Drop Out'. This is due to B0 field inhomogeneties. These are common near air ways (like the sinus cavity). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backup: What is B0?\n",
    "B0 = The external magnetic field  \n",
    "We use the RF pulse to 'knock' protons either 90 or 180 degrees, as they relax we measure the radiowaves they emit. We assume B0 is perfect, but like us, it never is. We can get around this by measuring B0 and mapping where it is no homogenous. \n",
    "\n",
    "![B0](https://github.com/grace-shearrer/fMRI_bootcamp2019/blob/weird/4dock/images/B0.gif?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concept Check:\n",
    "What scan can we run to measure B0?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIELDMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fMRIPREP B0 correction \n",
    "### What they call Susceptibility Distortion Correction (SDC)\n",
    "\n",
    "https://fmriprep.readthedocs.io/en/stable/sdc.html\n",
    "\n",
    "They do a very lovely job and mostly take all the confusion out of it.... if you know how to get fMRIPREP to work. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correction methods (from fMRIPREP)\n",
    "1. Phase Encoding POLARity (PEPOLAR) techniques (also called blip-up/blip-down): acquire at least two images with varying PE directions. Hence, the realization of distortion is different between the different acquisitions. The displacements map ùëëPE(ùë•,ùë¶,ùëß) is estimated with an image registration process between the different PE acquisitions, regularized by the readout time ùëáro. Corresponds to 8.9.4 of BIDS.  \n",
    " - Translation: You have two EPI (functional images) in different phase encoding directions. Compare the two directions and see where it is different.\n",
    "2. Direct B0 mapping sequences: some sequences (such as SE) are able to measure the fieldmap Œîùêµ0(ùë•,ùë¶,ùëß) directly. Corresponds to section 8.9.3 of BIDS. \n",
    " - Translation: Measure the field map directly with a higher order shim. (This is then applied to all your other images and you avoid having to re-shim before each EPI). FMRIPREP takes the image and then masks it with the magnitude image (thus why the skull strip is so important)\n",
    "\n",
    "3. Phase-difference B0 estimation: to estimate the fieldmap Œîùêµ0(ùë•,ùë¶,ùëß), these methods measure the phase evolution in time between two close GRE acquisitions. Corresponds to the sections 8.9.1 and 8.9.2 of the BIDS specification.  \n",
    " - Translation: Take two back to back gradient echo sequences and compare the phase drift.  You find the GRE in the T2* images. More (and better) explanation here http://mriquestions.com/gradient-echo.html\n",
    "\n",
    "4. Fieldmap-less estimation (experimental): FMRIPREP now experimentally supports displacement field estimation in the absence of fieldmaps via nonlinear registration.  \n",
    " - This is honestly what blew me away with fMRIPREP. The experimental fieldmap estimation does an astonishingly good job. This is using FNIRT (non-linear estimation) to correct for articfacts. We will touch back on this in the registration topic\n",
    "\n",
    "5. Point-spread function acquisition: Not supported by FMRIPREP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept check: T2* That sounds familiar? .... What do we usually refer to as the T2*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOLD sequences are frequently refered to as T2*\n",
    "Though here are many T2* sequences and using a 180 degree pulse will eliminate dephasing levaing only the \"true\" T2 image\n",
    "Excellent paper on the topic: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2799958/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B0 correction in FSL Fugue and Prelude\n",
    "What you need (Siemens):\n",
    "- Phase image\n",
    "- Magnitude image (brain extracted - see note below)\n",
    "- Difference of Echo Times - this is a sequence parameter that your scanner operator/radiographer/technician should know, but make sure you record the value\n",
    "\n",
    "These are the typical field map images you generally generate. \n",
    "\n",
    "![FM_mag](https://github.com/grace-shearrer/fMRI_bootcamp2019/blob/weird/4dock/images/fieldmap_mag.png?raw=true)\n",
    "\n",
    "![FM_pd](https://github.com/grace-shearrer/fMRI_bootcamp2019/blob/weird/4dock/images/fieldmap_phase_difference.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artefacts are compensated by  \n",
    "1. geometrically unwarping the EPI images, and  \n",
    "2. applying cost-function masking in registrations to ignore areas of signal loss  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issues with fieldmaps\n",
    "- If it is a bad fieldmap it isn't going to help. Good to check if there are distortions in the fieldmap. \n",
    "- Sometimes it just isn't enough. You need good registation and motion correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slice timing correction\n",
    "We can't aquire all slices at once, but our model assumes they all are collected at once.  \n",
    "_All images from Jeannette Mumford's MRI class at UT Austin_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept check: What is a TR?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR= Repition time\n",
    "The time it takes to image the entire field of view (often the entire brain). How many slices can you get per TR? How do you know that one slice doesn't 'bleed' into the next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tr_image](https://github.com/grace-shearrer/fMRI_bootcamp2019/blob/weird/4dock/images/slicetime.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![shift](https://github.com/grace-shearrer/fMRI_bootcamp2019/blob/weird/4dock/images/shift.png?raw=true)"
    "![FM_mag](https://github.com/grace-shearrer/fMRI_bootcamp2019/blob/weird/4dock/images/B0.gif?raw=true)\n",
    "\n",
    "![FM_pd](https://github.com/grace-shearrer/fMRI_bootcamp2019/blob/weird/4dock/images/B0.gif?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![interpolate](https://github.com/grace-shearrer/fMRI_bootcamp2019/blob/weird/4dock/images/interpolate.png?raw=true)"
    "Artefacts are compensated by  \n",
    "1. geometrically unwarping the EPI images, and  \n",
    "2. applying cost-function masking in registrations to ignore areas of signal loss  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issues with fieldmaps\n",
    "- If it is a bad fieldmap it isn't going to help. Good to check if there are distortions in the fieldmap. \n",
    "- Sometimes it just isn't enough. You need good registation and motion correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slice timing correction\n",
    "We can't aquire all slices at once, but our model assumes they all are collected at once.  \n",
    "_All images from Jeannette Mumford's MRI class at UT Austin_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept check: What is a TR?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR= Repition time\n",
    "The time it takes to image the entire field of view (often the entire brain). How many slices can you get per TR? How do you know that one slice doesn't 'bleed' into the next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tr_image](https://github.com/grace-shearrer/fMRI_bootcamp2019/blob/weird/4dock/images/B0.gif?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![shift](https://github.com/grace-shearrer/fMRI_bootcamp2019/blob/weird/4dock/images/B0.gif?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![interpolate](https://github.com/grace-shearrer/fMRI_bootcamp2019/blob/weird/4dock/images/B0.gif?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issues with slice timing correction:\n",
    "- One bad point, is now spread across the data.  \n",
    "- Not great if you have a high motion task/population\n",
    "- Usually used for event related designs (but again think about the motion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip slice time?\n",
    "This is a study specific choice point. If you are using a TR >= 2 with interleaved aquisition, you might not need it. Especially with a block design. \n",
    "Adding temporal derivatives is probably a better bet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motion correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of motion \n",
    "Physiological motion  \n",
    "- breathing\n",
    "- cardiac\n",
    "\n",
    "Head motion  \n",
    "- prospective\n",
    "- retrospective   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Physiological motion\n",
    "Generally low frequency (< 0.01Hz) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept Check: What kind of scan can be most vulerable to physiological motion? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resting state\n",
    "since we are often interest in lower frequency ranges (0.01 - 0.1 Hz). However, with BOLD there is the unfortunate problem of the cardiac and respiratory noise being correlated with BOLD response..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ways to correct on the front end:  \n",
    "- Breath hold\n",
    "- Respiratory/cardiac gating  \n",
    "- Measure pulse\n",
    "\n",
    "Ways to correct on the back end:\n",
    "- Temportal filtering\n",
    "- Regress motion parameters\n",
    "- CompCor (PCA, where the voxels with high variability are converted to a set of linearly uncorrelated values)  \n",
    "- ICA (tough to tell what is signal and noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Head motion  \n",
    "- prospective\n",
    "- retrospective "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prospective\n",
    "Usually called something like PACE. \n",
    "_THIS IS STANDARD AT BRIC UNLESS YOU TELL THEM TO TURN IT OFF_   \n",
    "This will measure the motion and update the sequence. This sounds lovely until someone moves a lot, then you can lose data. This is getting better with improved tech. However, with PACE you cannot also get uncorrected images. For resting state PACE maybe more advantagous, however I (personal opinion) would rather have my raw task images.\n",
    "Good paper: https://www.sciencedirect.com/science/article/pii/S1053811916306218"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrospective (MCFLIRT, DVARS, FD)\n",
    "Both FSL and fMRIPREP use MCFLIRT to estimate head motion and generate 6-parameters:\n",
    "- 3 rotations\n",
    "- 3 translations  \n",
    "\n",
    "In the fMRIPREP confounds file you will see the following:\n",
    "- trans_x \n",
    "- trans_y \n",
    "- trans_z \n",
    "- rot_x   \n",
    "- rot_y   \n",
    "- rot_z\n",
    "\n",
    "You can then create confound explanatory variables (EVs) from these and feed them into your model as EVs of no interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCFLIRT\n",
    "## Purpose  \n",
    "Align each voxel with subsequent voxels in the timeseries.  \n",
    "## How  \n",
    "Register each frame with 6 degrees of freedom to a reference image. \n",
    "## Output\n",
    "Plot of how much each frame needed to be adjusted to the reference image overtime. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept check: What is the default reference image? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The median image in the timeseries\n",
    "What are some pros and cons t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not using fMRIPREP? No problem\n",
    "You can just run mcflirt through a GUI or the command line in FSL. I also have created a wrapper script (python) that allows you to run MCFLIRT and it will create the 6 motion parameters ready to be fed into FEAT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def prepro(basedir, args, arglist, outhtml, out_bad_bold_list,DATA):\n",
    "    #bet\n",
    "    if args.STRIP==True:\n",
    "        print(\"starting bet\")\n",
    "\n",
    "        for sub in DATA:\n",
    "            for nifti in glob.glob(os.path.join(sub,'func','sub-*_task-%s_bold.nii.gz')%(arglist['TASK'])):\n",
    "                input=nifti\n",
    "                output=nifti.strip('.nii.gz')\n",
    "                if os.path.exists(output+'_brain.nii.gz'):\n",
    "                    print(output+' exists, skipping')\n",
    "                else:\n",
    "                    BET_OUTPUT=output+'_brain'\n",
    "                    x=(\"/usr/local/fsl/bin/bet %s %s -F\"%(input, BET_OUTPUT))\n",
    "                    os.system(x)\n",
    "                    \n",
    "\n",
    "#bet rage\n",
    "    if args.RAGE==True:\n",
    "        print(\"starting bet rage\")\n",
    "        for sub in DATA:\n",
    "            for input in glob.glob(os.path.join(sub,'anat','*T1w.nii.gz')):\n",
    "                output=input.strip('.nii.gz')\n",
    "                print(output)\n",
    "                if os.path.exists(output+'_brain.nii.gz'):\n",
    "                    print(output+' exists, skipping')\n",
    "                else:\n",
    "                    BET_OUTPUT=output+'_defaced'\n",
    "                    x=(\"/usr/local/fsl/bin/bet %s %s -R\"%(input, BET_OUTPUT))\n",
    "                    print(x)\n",
    "                    os.system(x)\n",
    "                    \n",
    "       \n",
    "# motion correction\n",
    "    if args.MOCO==False:\n",
    "        print(\"No motion correction performed\")\n",
    "    else:\n",
    "        print(\"starting motion correction\")\n",
    "        for sub in DATA:\n",
    "            for dir in glob.glob(os.path.join(sub,'func')):\n",
    "                if not os.path.exists(os.path.join(basedir,dir,'motion_assessment')):\n",
    "                    os.makedirs(os.path.join(basedir,dir,'motion_assessment'))\n",
    "                os.chdir(os.path.join(basedir, dir))\n",
    "                for input in glob.glob('*brain.nii.gz'):\n",
    "                    output=input.split('.')[0]\n",
    "                    print(output)\n",
    "                    if output.endswith('mcf'):\n",
    "                        print(output+' exists, skipping')\n",
    "                    else:\n",
    "                        os.system(\"mcflirt -in %s -plots\"%(output))\n",
    "                        os.system(\"fsl_motion_outliers -i %s -o motion_assessment/%s_confound.txt --fd --thresh=%s -p motion_assessment/fd_plot -v > motion_assessment/%s_outlier_output.txt\"%(output,output,arglist['MOCO'],output))\n",
    "                        os.system(\"cat motion_assessment/%s_outlier_output.txt >> %s\"%(output,outhtml))\n",
    "                        plotz=os.path.join(basedir,dir,'motion_assessment','fd_plot.png')\n",
    "                        os.system(\"echo '<p>=============<p>FD plot %s <br><IMG BORDER=0 SRC=%s WIDTH=%s></BODY></HTML>' >> %s\"%(output,plotz,'100%', outhtml))\n",
    "                    \n",
    "                        if os.path.isfile(\"motion_assessment/%s_confound.txt\"%(output))==False:\n",
    "                            os.system(\"touch motion_assessment/%s_confound.txt\"%(output))\n",
    "                        \n",
    "                        check = subprocess.check_output(\"grep -o 1 motion_assessment/%s_confound.txt | wc -l\"%(output), shell=True)\n",
    "                        num_scrub = [int(s) for s in check.split() if s.isdigit()]\n",
    "                        \n",
    "                        if num_scrub[0]>45:\n",
    "                            with open(out_bad_bold_list, \"a\") as myfile:\n",
    "                                myfile.write(\"%s\\n\"%(output))\n",
    "                            myfile.close()\n",
    "                            \n",
    "                        if os.path.exists(\"%s_mcf.par\"%(output)):\n",
    "                            if os.path.exists(os.path.join(basedir,dir,'motion_assessment',\"%s_mcf.par\"%(output))):\n",
    "                                    os.remove(os.path.join(basedir,dir,'motion_assessment',\"%s_mcf.par\"%(output)))\n",
    "\n",
    "                        shutil.move(\"%s_mcf.par\"%(output),os.path.join(basedir,dir,'motion_assessment'))\n",
    "                        rawfile = open(os.path.join(os.path.join(basedir,dir,'motion_assessment','%s_mcf.par'%(output))), 'r')\n",
    "                        table = [line.rstrip().split() for line in rawfile.readlines()]\n",
    "                        for i in range(6):\n",
    "                            newtable = ([[line[i]] for line in table])\n",
    "                            f=open(os.path.join(basedir,dir,'motion_assessment','%s_motcor%i.txt'%(output,i)),'w')\n",
    "                            for item in newtable:\n",
    "                                neat=item[0]\n",
    "                                f.write(str(neat)+'\\n')\n",
    "                            f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def main(DATA):\n",
    "    import glob\n",
    "    import os\n",
    "    import subprocess\n",
    "    import argparse\n",
    "    import shutil\n",
    "    basedir='/Users/gracer/Desktop/data'\n",
    "    writedir='/Users/gracer/Desktop/data'\n",
    "    \n",
    "    datestamp=datetime.datetime.now().strftime(\"%Y-%m-%d-%H_%M_%S\")\n",
    "    outhtml = os.path.join(writedir,'bold_motion_QA_%s.html'%(datestamp))\n",
    "    out_bad_bold_list = os.path.join(writedir,'lose_gt_45_vol_scrub_%s.txt'%(datestamp))\n",
    "\n",
    "    parser=argparse.ArgumentParser(description='preprocessing')\n",
    "    parser.add_argument('-task',dest='TASK',\n",
    "                        default=False, help='which task are we running on?')\n",
    "    parser.add_argument('-bet',dest='STRIP',action='store_true',\n",
    "                        default=False, help='bet via fsl using defaults for functional images')\n",
    "    parser.add_argument('-betrage',dest='RAGE',action='store_true',\n",
    "                        default=False, help='bet via fsl using robust estimation for anatomical images')\n",
    "    parser.add_argument('-moco',dest='MOCO',\n",
    "                        default=False, help='this is using fsl_motion_outliers to preform motion correction and generate a confounds.txt as well as DVARS')\n",
    "    args = parser.parse_args()\n",
    "    arglist={}\n",
    "    for a in args._get_kwargs():\n",
    "        arglist[a[0]]=a[1]\n",
    "    print(arglist)\n",
    "    prepro(basedir, args, arglist, outhtml, out_bad_bold_list,DATA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# POP QUIZ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the equation for a line ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y = mX+b\n",
    "where m = (delta Y/ delta X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we apply a line to 4D data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can think of our data as a really, really big matrix of numbers. \n",
    "An important caveat between FSL and SPM:\n",
    "- FSL uses 4D NIFTI image (what we will be using today)\n",
    "- SPM uses multiple 3D NIFTI images (one per TR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical error/Disturbance\n",
    "How much does a single value differ from the TRUTH.  \n",
    "Generally impossible to know.  \n",
    "We use the normal distribution to try and standardize statistical errors. AKA, we made up a population and we'll be damned if we aren't going to use it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residuals\n",
    "Difference between the true phenomenon being studied and the model being employed to describe it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error  \n",
    "\n",
    "### Systemic  \n",
    "1. Instrumental  \n",
    "  - The magnet isn't calibrated correctly (this is mostly up to the MR techs, but it is not out of the question to ask for their QA)   \n",
    "2. Observational  \n",
    "  - In ability to observe the correct measure  \n",
    "3. Enviromental  \n",
    "  - RF leak in the magnet room (really really annoying)\n",
    "4. Theoretical  \n",
    "  - Your model isn't correct. Could be a problem in the Fourier transformation or HRF.     \n",
    "\n",
    "### Random\n",
    "1. Observational  \n",
    "  - Not measuring to the appropriate divison \n",
    "  - Ex. Your measuring height to the .001cm, but your stadiometer only measures to the 0.1  \n",
    "2. Enviromental \n",
    "  - Unpredictable fluctuations \n",
    "  - Ex. Random power surge due to construction\n",
    "  - Ex. You randomly pet a cat some days and it spooks your mice  \n",
    "\n",
    "### Blunders  \n",
    "Ya done f'd up. Typed in the wrong value. Coded your contrast wrong. It happens.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Noise\n",
    "_Data = true + noise_  \n",
    "\n",
    "All data is noisy! As much as we would love to have perfect data this is rarely the case. \n",
    "\n",
    "Unlike error. Noise can only really be corrected using statistical modeling, and this is limited to the measurement device."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sources of noise\n",
    "### Random\n",
    "_OMG! UR SO RANDOM!_\n",
    "Also called white noise. All data will have some random noise, we are never perfect and neither is data. Where does it come from?  \n",
    "#### Error in measurement tools\n",
    "1) Gross Errors\n",
    "Miss reading the measurement. \n",
    "#### Error from processing or human error\n",
    "2) Blunders\n",
    "\n",
    "3) Measurement Errors\n",
    "- Systemic\n",
    "- Random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) the residual is the difference between the true phenomenon being studied and the model being employed to describe it.\n",
    "2) noise is that part of the residual which is in-feasible to model by any other means than a purely statistical description. note that such modelling limitations also arise due to limitations of the measurement device (e.g. finite bandwidth & resolution).\n",
    "3) error is that component of the residual that remains after accounting for the noise.\n",
    "according to the above definitions:\n",
    "a) noise and error are uncorrelated\n",
    "b) residual may be reduced by either reducing noise or by reducing error\n",
    "c)  these definitions are compatible with the intuitive statements that \"noise does not introduce bias\" and \"bias is a class of error\".\n",
    "finally note that error can only be reduced by improving the model (either of the phenomenon or of the measurement process). however noise may be reduced by either improving the measurement device, or by improving the model fidelity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Open up a fresh blank script in your Spyder IDE and save it as prepro.py\n",
    "For this tutorial you will input all code into this script and periodically commit your changes and push them to github when you see the logo \n",
    "![](https://imageog.flaticon.com/icons/png/512/3/3641.png?size=1200x630f&pad=10,10,10,10&ext=png&bg=FFFFFFFF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## First thing we will always do is load our modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pdb\n",
    "import subprocess\n",
    "import argparse\n",
    "import datetime\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Often times we won't know all the modules we want to import right off the bat  but I like to make sure that as I am scripting I always put my modules at the top. \n",
    "### This allows others who may use my script to make sure they have all the necessary tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Now lets start by building a function that will hold all the commands we want to execute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "```\n",
    "def prepro():\n",
    "    #do something cool\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## We will make a function that will hold all of our global variables and our above function\n",
    "## I personally like to call this main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```\n",
    "def main():\n",
    "    prepro()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Finally we have our two functions and lastly we will call our main( ) which will execute both our global variables and our command function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def prepro(basedir):\n",
    "    #Do something cool\n",
    "    print('Hello data in the path '+basedir)\n",
    "def main():\n",
    "    #load in all the global variables prepro needs, right now this is just the path to the data\n",
    "    basedir='/Users/gracer/Desktop/data' \n",
    "    prepro(basedir) #call prepro to do cool things "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()#call main to execute all our globals then run our prepro function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://imageog.flaticon.com/icons/png/512/3/3641.png?size=1200x630f&pad=10,10,10,10&ext=png&bg=FFFFFFFF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  What do we want the function to accomplish:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "1. skull stripping\n",
    "2. motion correction\n",
    "  * creating motion regressors\n",
    "  * creating framewise displacement regressor\n",
    "  * a nice easy to read PDF/html?\n",
    "3. re-orient?\n",
    "4. trim extra TRs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's fill in our main( ) function first with the global variables we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    basedir='/Users/gracer/Desktop/data'\n",
    "    prepro()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Anything you define in the main( ) function has to become an argument in the prepro( ) function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def prepro(basedir):\n",
    "    print('Hello data in the path '+basedir)\n",
    "def main():\n",
    "    basedir='/Users/gracer/Desktop/data'\n",
    "    prepro(basedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's start with skull stripping using fsl's BET function. \n",
    "## This is a linux based command so we are going to need to use a module to python to understand it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Normally at the command line we would run something like this:\n",
    "\n",
    "```\n",
    "bet input output [options]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## In python we can use the os module to run linux commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```\n",
    "os.system(bet input output -F)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#try running this \n",
    "\n",
    "print(os.system('echo $FSLDIR'))\n",
    "\n",
    "\n",
    "#now look at the terminal you launched your jupyter notebook from\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## next lets take a close look at the input and output we need. What will the input look like? What do we want the output to look like?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "input='/Users/gracer/Desktop/data/<subject number>/func/<nifiti_file>'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Each time we run this command the only things we really need to change are the subject number and the name of the nifti file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Our subject numbers and nifti files use a predictable pattern! \n",
    "## We can use the glob module to find everything with a similar pattern. \n",
    "## Here we are going to use a wildcard character (*) to represent the portions of the subject number that differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input=glob.glob('/Users/gracer/Desktop/data/sub-*/func/sub-*.nii.gz')\n",
    "print(input[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## glob has created a list with everything matching our pattern criteria. We can use any of python's list comprehension tools to further explore the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## We can also take any element from the list and make it a string. By making a string we can grab IDs or other parts of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#x=input[1]\n",
    "#print('my path is '+x)\n",
    "#y=x.split('/')\n",
    "#print (y)\n",
    "#whatcomp=y[2]\n",
    "#sub=y[5]\n",
    "#print sub\n",
    "\n",
    "sub=input[1].split('/')[5]\n",
    "print(sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's make this look a little nicer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub=input[1].split('/')[5]\n",
    "print(sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Now we have the subject number but it looks like we have multiple tasks. How can we split an element from the list to get the task information and the subject information?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subtask=input[1].split('/')[7].split('.')[0]\n",
    "#subtask=subtask.strip('.nii.gz')\n",
    "print(subtask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output=subtask+'_brain'\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lets go back to our bet command in the os wrapper. We now have all the elements we need to execute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "os.system('bet' x output '-F')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## This is a problem, we have our input defined, but it looks like os.system is expecting a string argument. \n",
    "## We need to use another wildcare to pass our variables as strings! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#os.system('bet' x output '-F')\n",
    "#print(x)\n",
    "#print(output)\n",
    "os.system('bet %s %s -F'%(x, output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The %s is a placeholder for string variable\n",
    "The **%** lets python know to look to the % sign outside the string for the variable of interest. \n",
    "We could also use this to pass **integers and floats using %i and %f** respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Now we have the ability to run bet through python on one subject.... but what about all the other scans.... ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](https://i.imgur.com/itVtNcK.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "input=glob.glob('/Users/gracer/Desktop/data/sub-*/func/sub-*.nii.gz')\n",
    "#print input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## this is a little long to type each time, \n",
    "## and it is really easy to mess up the / formating "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## os.path.join( ) is super useful to quickly define paths. It will format strings into paths and allows us to use the %s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#input=glob.glob('/Users/gracer/Desktop/data/sub-*/func/sub-*.nii.gz')\n",
    "basedir='/Users/gracer/Desktop/data'\n",
    "path=os.path.join(basedir,'sub-*','func','sub-*.nii.gz')\n",
    "#print(path)\n",
    "#input=glob.glob(path)\n",
    "#len(input[1:5])\n",
    "os.path.exists(basedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's put this altogether into our function prepro( ) with a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepro(basedir):\n",
    "    for item in glob.glob(os.path.join(basedir,'sub-*','func','sub-*.nii.gz')):\n",
    "        input=item\n",
    "        output_path=item.strip('.nii.gz')\n",
    "        output=output_path+('_brain')\n",
    "        os.system(\"/usr/local/fsl/bin/bet %s %s -F\"%(input, output))\n",
    "        pdb.set_trace()\n",
    "def main():\n",
    "    basedir='/Users/gracer/Desktop/data'\n",
    "    prepro(basedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://imageog.flaticon.com/icons/png/512/3/3641.png?size=1200x630f&pad=10,10,10,10&ext=png&bg=FFFFFFFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main()\n",
    "#prepro(os.path.join('Users','gracer','Desktop','data'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept Check: Why do we have to type main( ) after def prepro( ) and def main( )? Why do we have 2 functions? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ta Da!!! You have your first preprocessing script! \n",
    "### But wait... how do you make sure you don't end up running the same function on the same data over and over?\n",
    "### Let's write in a check statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## We can use os.path.exists( ) to check if we have already run BET, and tell our function to skip that subject\n",
    "### This is useful if you have two people preprocessing data, or if something happens (aka your computer runs out of power) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepro(basedir):\n",
    "    for item in glob.glob(os.path.join(basedir,'sub-*','func','sub-*.nii.gz')):\n",
    "        input=item\n",
    "        output_path=item.strip('.nii.gz')\n",
    "        output=output_path+'_brain.nii.gz'\n",
    "        print(output)\n",
    "        pdb.set_trace()\n",
    "        if os.path.exists(output):\n",
    "            print(output_path+' is already stripped')\n",
    "        else:\n",
    "            os.system(\"/usr/local/fsl/bin/bet %s %s -F\"%(input, output))\n",
    "        #pdb.set_trace()\n",
    "def main():\n",
    "    basedir='/Users/gracer/Desktop/data'\n",
    "    prepro(basedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "main()\n",
    "#%clear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://imageog.flaticon.com/icons/png/512/3/3641.png?size=1200x630f&pad=10,10,10,10&ext=png&bg=FFFFFFFF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Now that we know how:\n",
    "1. To make a set of functions\n",
    "2. Set our global variables\n",
    "3. Wrap our linux commands\n",
    "4. Use glob to get all our subjects through wildcard matching\n",
    "5. Loop through our list of subjects (from glob)\n",
    "6. Use string comprehension to format file names\n",
    "7. Use if/else loops to check for existing data\n",
    "\n",
    "\n",
    "### Try writing a function to skull strip a T1w scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def prepro(basedir, args, arglist, DATA):\n",
    "#bet\n",
    "    if args.STRIP==True:\n",
    "        for sub in DATA:\n",
    "            for nifti in glob.glob(os.path.join(sub,'func','sub-*_task-%s_bold.nii.gz')%(arglist['TASK'])):\n",
    "                input=item\n",
    "                output_path=item.strip('.nii.gz')\n",
    "                output=output_path+'_brain.nii.gz'\n",
    "                print(output)\n",
    "            \n",
    "                if os.path.exists(output):\n",
    "                    print(output_path+' is already stripped')\n",
    "                else:\n",
    "                    os.system(\"/usr/local/fsl/bin/bet %s %s -F\"%(input, output))\n",
    "#bet rage\n",
    "    if args.RAGE==True:\n",
    "        print(\"starting bet rage\")\n",
    "        for sub in DATA:\n",
    "            for input in glob.glob(os.path.join(sub,'anat','*T1w.nii.gz')):\n",
    "                output=input.strip('.nii.gz')\n",
    "                print(output)\n",
    "                if os.path.exists(output+'_brain.nii.gz'):\n",
    "                    print(output+' exists, skipping')\n",
    "                else:\n",
    "                    BET_OUTPUT=output+'_defaced'\n",
    "                    x=(\"/usr/local/fsl/bin/bet %s %s -R\"%(input, BET_OUTPUT))\n",
    "                    print(x)\n",
    "                    os.system(x)\n",
    "   \n",
    "def main(DATA):\n",
    "    basedir='/Users/gracer/Desktop/data'\n",
    "    parser=argparse.ArgumentParser(description='preprocessing')\n",
    "    parser.add_argument('-task',dest='TASK',\n",
    "                        default=False, help='which task are we running on?')\n",
    "    parser.add_argument('-bet',dest='STRIP',action='store_true',\n",
    "                        default=False, help='bet via fsl using defaults for functional images')\n",
    "    parser.add_argument('-betrage',dest='RAGE',action='store_true',\n",
    "                        default=False, help='bet via fsl using robust estimation for anatomical images')\n",
    "    args = parser.parse_args()\n",
    "    arglist={}\n",
    "    for a in args._get_kwargs():\n",
    "        arglist[a[0]]=a[1]\n",
    "    print(arglist)\n",
    "    prepro(basedir, args, arglist, DATA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Whoa what is all this extra stuff??? \n",
    "Let's take a look at all the new functionality that is possible "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## argparse\n",
    "This will allow us to give user defined arguments\n",
    "### Why would I make my life more complicated?\n",
    "\n",
    "- This is a good option for if you have multiple people working on preprocessing \n",
    "\n",
    "\n",
    "- You want to make one giant preprocessing script and have control over which commands are run  \n",
    "   \n",
    "   Instead of a bunch of smaller functions that infividually have to be called "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def main(DATA):\n",
    "    basedir='/Users/gracer/Desktop/data'\n",
    "    parser=argparse.ArgumentParser(description='preprocessing')\n",
    "    parser.add_argument('-task',dest='TASK',\n",
    "                        default=False, help='which task are we running on?')\n",
    "    parser.add_argument('-bet',dest='STRIP',action='store_true',\n",
    "                        default=False, help='bet via fsl using defaults for functional images')\n",
    "    parser.add_argument('-betrage',dest='RAGE',action='store_true',\n",
    "                        default=False, help='bet via fsl using robust estimation for anatomical images')\n",
    "    args = parser.parse_args()\n",
    "    arglist={}\n",
    "    for a in args._get_kwargs():\n",
    "        arglist[a[0]]=a[1]\n",
    "    print(arglist)\n",
    "    prepro(basedir, args, arglist, DATA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Define the parser, and give it a nice description \n",
    "\n",
    "```\n",
    "parser=argparse.ArgumentParser(description='preprocessing')\n",
    "\n",
    "```\n",
    "\n",
    "* Start thinking about arguments, these should be things that either trigger functionality or are global variables\n",
    "\n",
    "```\n",
    "parser.add_argument('-task',dest='TASK',\n",
    "                        default=False, help='which task are we running on?')\n",
    "parser.add_argument('-betrage',dest='RAGE',action='store_true',\n",
    "                        default=False, help='bet via fsl using robust estimation for anatomical images')\n",
    "\n",
    "```\n",
    "1. The first part is the flag, it will be entered with our script at the commandline\n",
    "2. Next is the destination, that is what the argparser is saving our input as\n",
    "3. We set the default to false, meaning you have to enter something for it to be true\n",
    "4. It is always nice to have a help especially if you are sharing your code!\n",
    "5. Action will store your variable, this is nice for instances where the presences of the flag indicates true\n",
    "\n",
    "\n",
    "* Put all our arguments in an variable called args\n",
    "\n",
    "```\n",
    "args = parser.parse_args()\n",
    "```\n",
    "\n",
    "* We could keep our arguments here and call them like this:\n",
    "\n",
    "```\n",
    "args.RAGE==True\n",
    "```\n",
    "\n",
    "* Personally I like putting them in a dictionary!\n",
    "\n",
    "```\n",
    "arglist={}\n",
    "    for a in args._get_kwargs():\n",
    "        arglist[a[0]]=a[1]\n",
    "```\n",
    "\n",
    "* Then you can call them in a dictionary form like this:\n",
    "\n",
    "```\n",
    "for nifti in glob.glob(os.path.join(sub,'func','sub-*_task-%s_bold.nii.gz')%(arglist['TASK'])):\n",
    "```\n",
    "\n",
    "* The key is 'TASK' and python will understand that to be what ever you entered into your argument list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://imageog.flaticon.com/icons/png/512/3/3641.png?size=1200x630f&pad=10,10,10,10&ext=png&bg=FFFFFFFF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What about motion correction and motion QA???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def prepro(basedir, args, arglist, outhtml, out_bad_bold_list,DATA):\n",
    "#def better(args,arglist,basedir):\n",
    "    #bet\n",
    "    if args.STRIP==True:\n",
    "        print(\"starting bet\")\n",
    "\n",
    "        for sub in DATA:\n",
    "            for nifti in glob.glob(os.path.join(sub,'func','sub-*_task-%s_bold.nii.gz')%(arglist['TASK'])):\n",
    "                input=nifti\n",
    "                output=nifti.strip('.nii.gz')\n",
    "                if os.path.exists(output+'_brain.nii.gz'):\n",
    "                    print(output+' exists, skipping')\n",
    "                else:\n",
    "                    BET_OUTPUT=output+'_brain'\n",
    "                    x=(\"/usr/local/fsl/bin/bet %s %s -F\"%(input, BET_OUTPUT))\n",
    "                    os.system(x)\n",
    "                    \n",
    "\n",
    "#bet rage\n",
    "    if args.RAGE==True:\n",
    "        print(\"starting bet rage\")\n",
    "        for sub in DATA:\n",
    "            for input in glob.glob(os.path.join(sub,'anat','*T1w.nii.gz')):\n",
    "                output=input.strip('.nii.gz')\n",
    "                print(output)\n",
    "                if os.path.exists(output+'_brain.nii.gz'):\n",
    "                    print(output+' exists, skipping')\n",
    "                else:\n",
    "                    BET_OUTPUT=output+'_defaced'\n",
    "                    x=(\"/usr/local/fsl/bin/bet %s %s -R\"%(input, BET_OUTPUT))\n",
    "                    print(x)\n",
    "                    os.system(x)\n",
    "                    \n",
    "\n",
    "       \n",
    "#motion correction\n",
    "    if args.MOCO==False:\n",
    "        print(\"No motion correction performed\")\n",
    "    else:\n",
    "        print(\"starting motion correction\")\n",
    "        for sub in DATA:\n",
    "            for dir in glob.glob(os.path.join(sub,'func')):\n",
    "                if not os.path.exists(os.path.join(basedir,dir,'motion_assessment')):\n",
    "                    os.makedirs(os.path.join(basedir,dir,'motion_assessment'))\n",
    "                os.chdir(os.path.join(basedir, dir))\n",
    "                for input in glob.glob('*brain.nii.gz'):\n",
    "                    output=input.split('.')[0]\n",
    "                    print(output)\n",
    "                    if output.endswith('mcf'):\n",
    "                        print(output+' exists, skipping')\n",
    "                    else:\n",
    "                        os.system(\"mcflirt -in %s -plots\"%(output))\n",
    "                        os.system(\"fsl_motion_outliers -i %s -o motion_assessment/%s_confound.txt --fd --thresh=%s -p motion_assessment/fd_plot -v > motion_assessment/%s_outlier_output.txt\"%(output,output,arglist['MOCO'],output))\n",
    "                        os.system(\"cat motion_assessment/%s_outlier_output.txt >> %s\"%(output,outhtml))\n",
    "                        plotz=os.path.join(basedir,dir,'motion_assessment','fd_plot.png')\n",
    "                        os.system(\"echo '<p>=============<p>FD plot %s <br><IMG BORDER=0 SRC=%s WIDTH=%s></BODY></HTML>' >> %s\"%(output,plotz,'100%', outhtml))\n",
    "                    \n",
    "                        if os.path.isfile(\"motion_assessment/%s_confound.txt\"%(output))==False:\n",
    "                            os.system(\"touch motion_assessment/%s_confound.txt\"%(output))\n",
    "                        \n",
    "                        check = subprocess.check_output(\"grep -o 1 motion_assessment/%s_confound.txt | wc -l\"%(output), shell=True)\n",
    "                        num_scrub = [int(s) for s in check.split() if s.isdigit()]\n",
    "                        \n",
    "                        if num_scrub[0]>45:\n",
    "                            with open(out_bad_bold_list, \"a\") as myfile:\n",
    "                                myfile.write(\"%s\\n\"%(output))\n",
    "                            myfile.close()\n",
    "                            \n",
    "                        if os.path.exists(\"%s_mcf.par\"%(output)):\n",
    "                            if os.path.exists(os.path.join(basedir,dir,'motion_assessment',\"%s_mcf.par\"%(output))):\n",
    "                                    os.remove(os.path.join(basedir,dir,'motion_assessment',\"%s_mcf.par\"%(output)))\n",
    "\n",
    "                        shutil.move(\"%s_mcf.par\"%(output),os.path.join(basedir,dir,'motion_assessment'))\n",
    "                        rawfile = open(os.path.join(os.path.join(basedir,dir,'motion_assessment','%s_mcf.par'%(output))), 'r')\n",
    "                        table = [line.rstrip().split() for line in rawfile.readlines()]\n",
    "                        for i in range(6):\n",
    "                            newtable = ([[line[i]] for line in table])\n",
    "                            f=open(os.path.join(basedir,dir,'motion_assessment','%s_motcor%i.txt'%(output,i)),'w')\n",
    "                            for item in newtable:\n",
    "                                neat=item[0]\n",
    "                                f.write(str(neat)+'\\n')\n",
    "                            f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def main(DATA):\n",
    "    basedir='/Users/gracer/Desktop/data'\n",
    "    writedir='/Users/gracer/Desktop/data'\n",
    "    \n",
    "    datestamp=datetime.datetime.now().strftime(\"%Y-%m-%d-%H_%M_%S\")\n",
    "    outhtml = os.path.join(writedir,'bold_motion_QA_%s.html'%(datestamp))\n",
    "    out_bad_bold_list = os.path.join(writedir,'lose_gt_45_vol_scrub_%s.txt'%(datestamp))\n",
    "\n",
    "    parser=argparse.ArgumentParser(description='preprocessing')\n",
    "    parser.add_argument('-task',dest='TASK',\n",
    "                        default=False, help='which task are we running on?')\n",
    "    parser.add_argument('-bet',dest='STRIP',action='store_true',\n",
    "                        default=False, help='bet via fsl using defaults for functional images')\n",
    "    parser.add_argument('-betrage',dest='RAGE',action='store_true',\n",
    "                        default=False, help='bet via fsl using robust estimation for anatomical images')\n",
    "    parser.add_argument('-moco',dest='MOCO',\n",
    "                        default=False, help='this is using fsl_motion_outliers to preform motion correction and generate a confounds.txt as well as DVARS')\n",
    "    args = parser.parse_args()\n",
    "    arglist={}\n",
    "    for a in args._get_kwargs():\n",
    "        arglist[a[0]]=a[1]\n",
    "    print(arglist)\n",
    "    prepro(basedir, args, arglist, outhtml, out_bad_bold_list,DATA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Yikes! This looks like a ton of new information! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## We actually are only adding a couple new elements\n",
    "### We are going to: \n",
    "1. Make a directory (folder)\n",
    "2. Save text output to a useful location\n",
    "3. Save our output plots to a single html\n",
    "4. Check our text output files for subjects for excessive motion\n",
    "5. Create our motion regressors\n",
    "6. Move everything into our directory we made (#1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1. Make a directory (folder)\n",
    "```\n",
    "            for dir in glob.glob(os.path.join(sub,'func')):\n",
    "                if not os.path.exists(os.path.join(basedir,dir,'motion_assessment')):\n",
    "                    os.makedirs(os.path.join(basedir,dir,'motion_assessment'))\n",
    "                os.chdir(os.path.join(basedir, dir))\n",
    "```\n",
    "Again we are using glob to get all our subjects.\n",
    "Next we are checking that a path exists (and therefore our directory) with the command\n",
    "```\n",
    "os.path.exists()\n",
    "```\n",
    "If it doesn't exist that means we need to make it.\n",
    "There are a lot of ways to make directories, but I like:\n",
    "```\n",
    "os.makedirs()\n",
    "```\n",
    "Finally, we are going to change directory into the subject we are on using:\n",
    "```\n",
    "os.chdir(os.path.join(basedir, dir))\n",
    "```\n",
    "#### Notice the indentation of the code above. The last line is not in the if statement loop.\n",
    "##### This is important because we want to change directory regardless whether the if statement is true or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### This should look familiar\n",
    "```\n",
    "                for input in glob.glob('*brain.nii.gz'):\n",
    "                    output=input.split('.')[0]\n",
    "                    print(output)\n",
    "                    if output.endswith('mcf'):\n",
    "                        print(output+' exists, skipping')\n",
    "                    else:\n",
    "                        os.system(\"mcflirt -in %s -plots\"%(output))\n",
    "                        os.system(\"fsl_motion_outliers -i %s -o motion_assessment/%s_confound.txt --fd --thresh=%s -p motion_assessment/fd_plot -v > motion_assessment/%s_outlier_output.txt\"%(output,output,arglist['MOCO'],output))\n",
    "```\n",
    "* Here we are getting all the files we previously skull stripped and using our familiar friend... \n",
    "* os.system() to run a linux command! This time mcflirt and fsl_motion_outliers\n",
    "* We have included a if/else statement to check if we have already done this (why waste our own time?)\n",
    "* We also are piping the output of the fsl_motion_outliers command to a text file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2. Save text output to a useful location\n",
    "os.system(\"cat motion_assessment/%s_outlier_output.txt >> %s\"%(output,outhtml))\n",
    "* This is very similar to above, again we are using os.system to execute a linux redirect\n",
    "* This time we are redirecting the text from the output file we made to a html \n",
    "* Why put this all in an html?\n",
    "   * html is useful for sharing the output\n",
    "   * We could embed it into a fancy shmancy jupyter notebook\n",
    "   * We could make a pdf and send it to our PI\n",
    "   * We could print it and wall paper our walls with QA reports!\n",
    "#### Concept check: where is the variable outhtml defined? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3. Save our output plots to a single html\n",
    "```\n",
    "plotz=os.path.join(basedir,dir,'motion_assessment','fd_plot.png')\n",
    "os.system(\"echo '<p>=============<p>FD plot %s <br><IMG BORDER=0 SRC=%s WIDTH=%s></BODY></HTML>' >> %s\"%(output,plotz,'100%', outhtml))\n",
    "```\n",
    "Here we are doing two things\n",
    "1. We are creating a variable called plotz, which is the path to our fd_plot.png\n",
    "2. We are formatting and entering the fd_plot.png into our html using os.system and linux commands to make sure it looks correct in the html \n",
    "\n",
    "#### Concept check: Think about the structure of the loop we are building, what is directly above the plot in our html?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4. Check our text output files for subjects for excessive motion\n",
    "```\n",
    "if os.path.isfile(\"motion_assessment/%s_confound.txt\"%(output))==False:\n",
    "    os.system(\"touch motion_assessment/%s_confound.txt\"%(output))\n",
    "                        \n",
    "check = subprocess.check_output(\"grep -o 1 motion_assessment/%s_confound.txt | wc -l\"%(output), shell=True)\n",
    "num_scrub = [int(s) for s in check.split() if s.isdigit()]\n",
    "                        \n",
    "if num_scrub[0]>45:\n",
    "    with open(out_bad_bold_list, \"a\") as myfile:\n",
    "        myfile.write(\"%s\\n\"%(output))\n",
    "    myfile.close()\n",
    "```\n",
    "1. We are using our favorite if/else statement to check that the confound.txt exists.\n",
    "  * But what about perfect subjects? They won't have a confound.txt??? HALP\n",
    "  * This is kinda great problem, and easy to fix, we are going to use \n",
    "  ```\n",
    "  os.system(\"touch motion_assessment/%s_confound.txt\"%(output))\n",
    "  ```\n",
    "  to create a blank text file with the correct name for our 1st level feats to find\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "2. Most of our particpants aren't perfectly still, so we want to create a check variable:\n",
    "  * We are using a new module called subprocess\n",
    "  * This operates very similar to os.system, but we can define the type of shell and use the additional check_output functionality to save our output to a variable\n",
    "  * So here we are searching for our confound.txt using grep, then we are counting the lines in the file (wc -l)\n",
    "    ```\n",
    "    check = subprocess.check_output(\"grep -o 1 motion_assessment/%s_confound.txt | wc -l\"%(output), shell=True)\n",
    "    num_scrub = [int(s) for s in check.split() if s.isdigit()]\n",
    "    ```\n",
    "3. Next we are creating a num_scrub variable:\n",
    "  * This is a weird looking loop!\n",
    "  * We could have also written it as:\n",
    "  ```\n",
    "  for s in check.split():\n",
    "      if s.isdigit:\n",
    "          num_scrub=int(s)\n",
    "  ```\n",
    "  * Basically we want to remove white space with split, check if it is a digit, and make it an integer if it is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "4. Great we have an integer now we can check if that integer is bigger or smaller than our \"bad\" criteria\n",
    "  * Our final loop compares our num_scrub to a criteria we set (45)\n",
    "  * If num_scrub is bigger we want to note it so we are going to open a file\n",
    "  ```\n",
    "  with open(out_bad_bold_list, \"a\") as myfile:\n",
    "  ```\n",
    "  * We are going to write the subject information to the file\n",
    "  ```\n",
    "  myfile.write(\"%s\\n\"%(output))\n",
    "  ```\n",
    "  * Then we are going to close the file\n",
    "  ```\n",
    "  myfile.close()\n",
    "  ```\n",
    "#### Important note: make sure you close the file outside the loop! Otherwise on the second loop it will try to write to closed file! Or it will try to open an already open file. Either way you won't be happy with the error.\n",
    "#### Bonus points: what is the \\n when we are writing the output to file? Why include this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5. Move everything into our directory we made (#1)\n",
    "```\n",
    "if os.path.exists(\"%s_mcf.par\"%(output)):\n",
    "    if os.path.exists(os.path.join(basedir,dir,'motion_assessment',\"%s_mcf.par\"%(output))):\n",
    "        os.remove(os.path.join(basedir,dir,'motion_assessment',\"%s_mcf.par\"%(output)))\n",
    "shutil.move(\"%s_mcf.par\"%(output),os.path.join(basedir,dir,'motion_assessment'))\n",
    "```\n",
    "Since we ran MCFLIRT using the -plot flag we should have a .par file\n",
    "1. We are checking that file exists, seeing if we already moved, if we already did we are deleting the old one\n",
    "```\n",
    "if os.path.exists(\"%s_mcf.par\"%(output)):\n",
    "    if os.path.exists(os.path.join(basedir,dir,'motion_assessment',\"%s_mcf.par\"%(output))):\n",
    "        os.remove(os.path.join(basedir,dir,'motion_assessment',\"%s_mcf.par\"%(output)))\n",
    "```\n",
    "2. We are moving the .par to our motion_assessment directory using the shutil command\n",
    "  * It is always a good idea to check that the file doesn't already exist\n",
    "  * Shutil won't overwrite a file instead it will error out\n",
    "  * Shutil uses the following formula \n",
    "  ```\n",
    "  shutil.move(path_file_to_move, path_to_new_file_location)\n",
    "  ```\n",
    "#### Bonus points: How could we use shutil.move to rename a file?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 6. Create our motion regressors\n",
    "##### Note: If you are planning on using MCFLIRT in FEAT you don't need this, but it is fun to learn right???\n",
    "```\n",
    "rawfile = open(os.path.join(os.path.join(basedir,dir,'motion_assessment','%s_mcf.par'%(output))), 'r')\n",
    "table = [line.rstrip().split() for line in rawfile.readlines()]\n",
    "for i in range(6):\n",
    "    newtable = ([[line[i]] for line in table])\n",
    "    f=open(os.path.join(basedir,dir,'motion_assessment','%s_motcor%i.txt'%(output,i)),'w')\n",
    "    for item in newtable:\n",
    "        neat=item[0]\n",
    "        f.write(str(neat)+'\\n')\n",
    "    f.close()\n",
    "```\n",
    "1. We are going to open our .par file as rawfile\n",
    "2. Gah! Another weird looking loop!\n",
    "```\n",
    "for line in rawfile.readlines():\n",
    "    table=line.rstrip().split()\n",
    "```\n",
    "   * We are reading in the rawfile line by line (readlines)\n",
    "   * We are removing the whitespace characters on the right (rstrip) and splitting it by white space (this makes the column)\n",
    "3. We always are going to have 6 motion parameters from MCFLIRT so we are setting a counter called i\n",
    "   * This counter is going to count up to 6\n",
    "   * Python likes to be a little difficult, and starts counting at 0, so our counter will count (0,1,2,3,4,5)\n",
    "4. Newtable is taking our inital table and raw data and making a new table in a list format \n",
    "```\n",
    "newtable = ([[line[i]] for line in table])\n",
    "```\n",
    "   * It is using our counter (i) to grab each line\n",
    "5. With our nice list we can now open a file to write to and each list item \n",
    "   * We are using the same counter so we don't mix up the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![](https://imageog.flaticon.com/icons/png/512/3/3641.png?size=1200x630f&pad=10,10,10,10&ext=png&bg=FFFFFFFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
