{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 4. Registration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why all the fuss? \n",
    "\n",
    "We need to be able to be able to generalize our findings. Both within our sample and overall. To do this we need to treat each scan like silly putty that isn't very stretchy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Space the final frontier\n",
    "\n",
    "We talk about a couple of general spaces\n",
    "1. Native space\n",
    "2. Standard Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Native Space\n",
    "The subject's personal space. If you look at enough images you realize these can be wildly different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Standard Space\n",
    "\n",
    "These are defined spaces.\n",
    "\n",
    "1. Talairach\n",
    " - Don't use\n",
    " - Based on a single woman\n",
    " - Please don't\n",
    "2. MNI\n",
    " - Based on 152 brains\n",
    " - Now a lot of different flavors (asym) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Steps for carrying out transformation\n",
    "1. Choose the type of transformation\n",
    "2. Estimate the parameters of the transformation\n",
    " - Requires a cost function to evaluate parameter choice\n",
    "3. Resample the original image\n",
    " - Transformed coordinates will not line up exactly with original coordinates\n",
    " - Use some type of interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Choose the type of transformation\n",
    "1. Rigid body (6 DOF)\n",
    " - within-subject motion\n",
    "2. Non-linear (lots of DOF!)\n",
    " - high-quality image (resolution, contrast) & same modality of reference/template\n",
    " - better with a non-linear template (e.g. MNI152_T1_2mm)\n",
    "3. Affine (12 DOF)\n",
    " - needed as a starting point for non-linear\n",
    " - align to affine template, or using lower quality images, or eddy current correction\n",
    "4. Global scaling (7 DOF)\n",
    "- within-subject but with global scaling (equal in x,y,z)\n",
    "- corrects for scanner scaling drift in longitudinal studies\n",
    "#### More DOF is NOT always better (e.g. within-subject)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![affine](https://github.com/grace-shearrer/fMRI_bootcamp2019/blob/wildwest/4dock/images/affine.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![spacey](https://github.com/grace-shearrer/fMRI_bootcamp2019/blob/wildwest/4dock/images/otherspaces.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Step 1\n",
    "![step1](https://github.com/grace-shearrer/fMRI_bootcamp2019/blob/wildwest/4dock/images/step1.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Step 2\n",
    "![step2](https://github.com/grace-shearrer/fMRI_bootcamp2019/blob/wildwest/4dock/images/step2.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Step 3\n",
    "![step3](https://github.com/grace-shearrer/fMRI_bootcamp2019/blob/wildwest/4dock/images/step3.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# All together\n",
    "![sofine](https://github.com/grace-shearrer/fMRI_bootcamp2019/blob/wildwest/4dock/images/sofine.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Nonlinear is where things get weird\n",
    "You have unlimited degrees of freedom and you essentially deforming a field.   \n",
    "I like to think I know a lot about MRI, but FNIRT is not one of them\n",
    "![warp](https://github.com/grace-shearrer/fMRI_bootcamp2019/blob/wildwest/4dock/images/warp.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Estimate the parameters of the transformation\n",
    "Or there is no free lunch  \n",
    "\n",
    "If you start pulling the brain like silly putty eventually it can become a big mess... But how big of a mess?\n",
    "\n",
    "We are measuring the 'goodness of fit'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## FLIRT FLAVORS\n",
    "1. Least Squares \n",
    " - Same modality\n",
    " - EXACT SAME (including brightness)\n",
    "2. Normalised Correlation \n",
    " - Same modality\n",
    " - can change brightness & contrast\n",
    " - What MCFLIRT uses\n",
    "3. Correlation Ratio \n",
    " - Any MR modalities\n",
    " - FSL standard\n",
    "4. Mutual Information \n",
    " - Any modalities\n",
    " - Including CT, PET, etc.\n",
    "5. Normalised Mutual Info. \n",
    " - Any modalities\n",
    " - including CT, PET, etc.\n",
    "6. BBR \n",
    " - Within-subject EPI to structural\n",
    " - see later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Resample the original image (interpolation)\n",
    "Try as we might we won't line up each voxel exactly. SO how can we estimate which is voxel goes where?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "1. Nearest Neighbor\n",
    " - The value of the new voxel is the nearest voxel from the original image\n",
    " - Lose resolution (images look blocky)\n",
    " - Useful when transformed image values must match original image\n",
    " - Mask images –  Atlases\n",
    "2. Linear interpolation (trilinear)\n",
    " - Take a weighted average of transformed voxels\n",
    " - Integrates over nearest 8 voxels in 3d •  Fast, but may blur the image  \n",
    "3. Higher Order Interpolation •  Sinc interpolation\n",
    " - A windowed sinc function is typically used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Concept Check:\n",
    "\n",
    "You have two  different types of images from\n",
    "the same subject: T1-weighted and T2-weighted images\n",
    "\n",
    "How can you align the images so that they can be\n",
    "used for multi-modal segmentation? How many DOF?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Rigid body 6-DOF\n",
    "The key here is it is the _same subject_ so we only need 6 DOF to align the images cause it is the _same brain_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Concept Check:\n",
    "What cost function should you use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Correlation or Normalized Mutual or Mutual Information\n",
    "The key here is you are registering two different *modalities*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Registration can go horribly wrong\n",
    "Ya gotta look at your images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# In FMRIPREP\n",
    "We haven't chatted a lot about fMRIPREP here cause well they do it the hard way. Which is great cause they took the hard part and automated it! \n",
    "\n",
    "To register the EPI through to native space they use BBR (boundry based registration). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Concept check: How many DOF do you think they use given they are using FLIRT?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 6-DOF! Same subject :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## To standard space\n",
    "### Who can translate this?\n",
    "\n",
    "This workflow concatenates the transforms calculated upstream (see Head-motion estimation, Susceptibility Distortion Correction (SDC) –if fieldmaps are available–, _EPI to T1w registration_, and an _anatomical-to-standard transform_ from T1w/T2w preprocessing) to map the EPI image to the standard spaces given by the --output-spaces argument (see Defining standard and nonstandard spaces where data will be resampled). It also maps the T1w-based mask to each of those standard spaces.\n",
    "\n",
    "Transforms are concatenated and applied all at once, with one interpolation (Lanczos) step, so as little information is lost as possible.\n",
    "\n",
    "The output space grid can be specified using modifiers to the --output-spaces argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "https://fmriprep.readthedocs.io/en/stable/_static/sample_report.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What does this look like in FSL FEAT?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example func to High res\n",
    "![x2res](https://github.com/grace-shearrer/fMRI_bootcamp2019/blob/wildwest/4dock/images/ex2hires.png?raw=true)\n",
    "\n",
    "### Note: The example_func is the image used to align all other images in MCFLIRT!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## High res to standard (MNI-152)\n",
    "![hi2stand](https://github.com/grace-shearrer/fMRI_bootcamp2019/blob/wildwest/4dock/images/hiRes2stand.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example_func to standard (MNI-152)\n",
    "![x2stand](https://github.com/grace-shearrer/fMRI_bootcamp2019/blob/wildwest/4dock/images/exfunc2standard.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# NOTE: IF YOU ARE IMPORTING FMRIPREP DATA TO FEAT YOU NEED TO WORK AROUND YOUR REGISTRATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "FEAT can do its thing cause it assumes you have run all your analyses in FEAT. When we pick and choose FEAT starts to miss folders and will fail. One such folder is the reg folder in lower level FEAT directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "def reg_check(basedir,IDmat):\n",
    "    for sub in glob.glob(os.path.join(basedir,'sub-*','grace_edit','*.feat')):\n",
    "        \n",
    "        if os.path.exists(os.path.join(sub,'reg_standard')):\n",
    "            shutil.rmtree(os.path.join(sub,'reg_standard'))\n",
    "            print('%s has the reg standard'%sub)\n",
    "        \n",
    "        for files in glob.glob(os.path.join(sub,'reg','*.mat')):\n",
    "            print(files)\n",
    "            os.remove(files)\n",
    "        \n",
    "        shutil.copy2(IDmat,os.path.join(sub,'reg'))\n",
    "        meanFUNC=os.path.join(sub,'mean_func.nii.gz')\n",
    "        regDIR=os.path.join(sub,'reg','standard.nii.gz')\n",
    "        shutil.copy2(meanFUNC,regDIR)\n",
    "        \n",
    "                    \n",
    "        \n",
    "            \n",
    "def main(BASEDIR):\n",
    "    basedir=BASEDIR\n",
    "    IDmat='/usr/local/fsl/etc/flirtsch/ident.mat'\n",
    "    reg_check(basedir,IDmat)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    BASEDIR='/Users/gracer/Desktop/data/derivatives/task'\n",
    "    main(BASEDIR)\n",
    "\n",
    "# check that reg_standard exists in the first level\n",
    "# if it exists delete:\n",
    "# delete all .mat files\n",
    "# copy the mean_func.nii.gz to reg/standard.nii.gz\n",
    "#check the voxel intensities in the stats/cope.nii.gz and reg_standard/stats/cope.nii.gz \n",
    "# need to be the same (level 1)\n",
    "# data dimension and pixel size should be the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "https://fsl.fmrib.ox.ac.uk/fslcourse/lectures/practicals/registration/index.html  \n",
    "https://fsl.fmrib.ox.ac.uk/fslcourse/lectures/reg.pdf  \n",
    "Jeannette Mumford's UT Austin Lecture notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# End Registration\n",
    "Take break"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
